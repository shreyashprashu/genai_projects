{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7347e1f-00a2-44ab-8a71-f83cb54a8eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is jupyter notebook running inside a virtual environment\n"
     ]
    }
   ],
   "source": [
    "print(\"This is jupyter notebook running inside a virtual environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0310f4-2f17-41eb-88bf-29700a24eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be9c58f-0375-4675-9519-73d7e308b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.41.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /Users/shreyashprashu/.pyenv/versions/3.8.10/envs/mypyvenvenv38/lib/python3.8/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88000a90-67c7-4cdd-8c9a-baaba54894d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d30b71-2d09-48b5-ab12-074488a2f3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:33:51.929929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399c91ad-6668-4fea-a19e-027bfa06c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = pipeline(task=\"conversational\",\n",
    "                   model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acbc71e5-218f-47ff-aedb-14fc4453ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"\"\"\n",
    "What are some fun activities I can do in Bangalore?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e97c0e-1020-4de7-8e79-684de2cdffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55d030b-4ae2-4d57-8d3c-cd508db542fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cba2e31-0ca2-4c71-886f-f52d870ccba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: b1a86bd2-fea9-4ec1-827f-5cbc294fb674\n",
      "user: \n",
      "What are some fun activities I can do in Bangalore?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14532e9-88c5-4b0f-89dd-90b1dc0364c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = chatbot(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544714ab-7e3d-4cb4-a28e-febb5a9b92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: b1a86bd2-fea9-4ec1-827f-5cbc294fb674\n",
      "user: \n",
      "What are some fun activities I can do in Bangalore?\n",
      "\n",
      "assistant:  Well, Banglore is a country located in the southeastern region of South Asia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d000ac8-eabc-44b2-9bd3-a473478364ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_message({\"role\":\"user\",\"content\":\"\"\" what other cities are located nearby the city we are talking about? \"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0afdc9-50fd-451e-a222-0943bb01fe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: b1a86bd2-fea9-4ec1-827f-5cbc294fb674\n",
       "user: \n",
       "What are some fun activities I can do in Bangalore?\n",
       "\n",
       "assistant:  Well, Banglore is a country located in the southeastern region of South Asia.\n",
       "user:  what other cities are located nearby the city we are talking about? "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3cca7-f04b-408f-b40b-a2ea4badd95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = chatbot(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c1f41-52d4-4c87-8db4-ef2554ddc14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c1a4de-e9a1-40eb-851d-26f7b22d166b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ef6ac3-2af7-4dc4-b029-3976b1cec67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a231f7cde464c74a454a8f45c3044a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ab48bf-a1d5-438b-96aa-280bc1871556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ac4ebf-0eab-4a4e-b0e7-db83c3ba153c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205a36f5616645f986a71dcdd1736eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268d7eb3b0be4a709fb44904e2ee708e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fbf2cd141e41109ffc10822534d8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca822f8a497d48bab572c6d061691ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beecea5344474f1db7ad29bbe8e8dba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cb8a60610f4ab9b6cda54974d3b9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ceddb63c444dfbf528ccee2631211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582bdb9440ea4e25b8bd4a3ec9739f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cb0b026236408dbaf95083a4d68b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda8fd5cc1a543099ca784415f2d16a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6385b9a0776f45c69279b589769bc823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0673175a3fbc428ea333f2814d30811f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "chatbot = pipeline(\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fba2ed-04eb-4253-bca4-a3f574af2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llama3(user_input):\n",
    "    # Initialize the conversation with the user's input\n",
    "    conversation = [{\"role\": \"user\", \"content\": user_input}]\n",
    "\n",
    "    # Generate a response from the chatbot\n",
    "    response = chatbot(conversation, do_sample=False, max_new_tokens=50)\n",
    "\n",
    "    # Extract the chatbot's response\n",
    "    chatbot_response = response[0][\"generated_text\"][1][\"content\"]\n",
    "\n",
    "    return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f777da-26bd-4956-ba2b-2fa46946b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n",
      "/Users/shreyashprashu/.pyenv/versions/3.8.10/envs/mypyvenvenv38/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/shreyashprashu/.pyenv/versions/3.8.10/envs/mypyvenvenv38/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x10d878f40>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreyashprashu/.pyenv/versions/3.8.10/envs/mypyvenvenv38/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Test the chatbot\n",
    "user_input = \"What's the best way to travel to Europe?\"\n",
    "response = chat_with_llama3(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8ddf3-6dc6-4059-a7cc-920b246540e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question\n",
    "user_input = \"What about traveling by train?\"\n",
    "response = chat_with_llama3(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1927a1-e291-4aa9-a1d1-b5052f3a1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"\\\"\")\n",
    "]\n",
    "\n",
    "input_ids = pipeline.tokenizer.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
    ").to(pipeline.device)\n",
    "\n",
    "attention_mask = input_ids.ne(pipeline.tokenizer.pad_token_id).to(pipeline.device)\n",
    "\n",
    "outputs = pipeline.model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(pipeline.tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1125c7a-1e22-4baf-bddb-563ee7eb241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
